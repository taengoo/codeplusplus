
SECTION 3: Core Node.js

3.1 Node.js File-Based Module System
	- Node.js require Function
	- Node.js Exports
	- Modules Best Practices
3.2 Important Globals
	- console
	- Timers
	- __filename and __dirname
	- process
	- Buffer
	- global
3.3 Core Modules
	- Consuming Core Modules
	- Path Module
	- fs Module
	- os Module
	- util Module
3.4 Reusing Node.js Code in the Browser
	- Introducing AMD
	- Setting Up RequireJS
	- Playing with AMD
	- Converting Node.js Code into Browser Code
3.5 Summary


----
SECTION 3: Core Node.js
----
Node.js ships with a number of built-in modules that provide a core set of features we can build upon. In this chapter, we will show the important parts of Node.js that every serious developer should be familiar with. The great thing about Node.js is that it is quite possible for the average developer to be completely aware of exactly how everything functions.

To successfully deliver large applications and work in sizable teams, we need a way of encapsulating complexity. JavaScript was originally designed to be read from top to bottom in a simplistic manner by a web browser, and files were loaded using <script> tags. As larger and larger applications have been written in JavaScript, two module systems (AMD and CommonJS) have been developed. They make code more manageable and reusable. Two patterns exist because the browser and server offer different challenges in terms of module-loading latency (network requests vs. file system). In this chapter, we will discuss these patterns and show how to reuse Node.js code in the browser.

One note about the code samples in this and every other chapter that uses multiple files is that the main entry point of the example is often called app.js following a Node.js community convention. So you should be able to run a sample as node app.js.


----
3.1 Node.js File-Based Module System
----
Kevin Dongaoor created CommonJS in 2009 with the goal to specify an ecosystem for JavaScript modules on the server. Node.js follows the CommonJS module specification. Following are a few salient points of the module system:
- Each file is its own module.
- Each file has access to the current module definition using the module variable.
- The export of the current module is determined by the module.exports variable.
- To import a module, use the globally available require function.

As always, it is best to jump right into the code. Let’s consider a simple example where we want to share a function in file foo.js with various parts of our application. To export the function from the file, we simply assign it to module.exports, as shown in Listing 3-1.

Listing 3-1. intro/base/foo.js
module.exports = function () {
    console.log('a function in file foo');
};

In order to use this function from a file bar.js, we simply import foo using the globally available require function and store the returned value in a local variable, as shown in Listing 3-2.

Listing 3-2. intro/base/bar.js
var foo = require('./foo');
foo(); // logs out : "a function in file foo"

Node.js was designed to be simple, and this shows in its module system. Now that we have seen a simple example, let’s dig deeper into various details, starting with the require function.

----
Node.js require Function
----
The Node.js require function is the main way of importing a module into the current file. There are three kinds of modules in Node.js: core modules, file modules, and external node_modules, all of which use the require function. We are discussing file modules at the moment.

When we make a require call with a relative path—for example, something like require('./filename') or require('../foldername/filename')—Node.js runs the destination JavaScript file in a new scope and returns whatever was the final value for module.exports in that file. This is the basis of file modules. Let’s look at the ramifications of this design.

Node.js Is Safe
----
Modules in many programming environments are not safe and pollute the global scope. A simple example of this is PHP. Say you have a file foo.php that simply defines a function foo, as shown in Listing 3-3.

Listing 3-3. foo.php
function foo($something){
        return $something;
}

If you want to reuse this function in a file bar.php, you can simply include foo.php using the include function, and then everything from the file foo.php becomes a part of the (global) scope of bar.php. This allows you to use the function foo, as shown in Listing 3-4.

Listing 3-4. include Function in PHP
include('foo.php');
foo();

This design has quite a few negative implications. For example, what a variable foo means in a current file may change based on what you import. As a result, you cannot safely include two files, foo1 and foo2, if there is a chance that they have some variable with the same name. Additionally, everything gets imported, so you cannot have local only variables in a module. You can overcome this in PHP using namespaces, but Node.js avoids the potential of namespace pollution altogether.

Using the require function only gives you the module.exports variable, and you need to assign the result to a variable locally in order to use it in scope, as shown in Listing 3-5.

Listing 3-5. Code Snippet to Show That You Control the Name
var yourChoiceOfLocalName = require('./foo');

There is no accidental global scope—there are explicit names and files with similar internal local variable names that can coexist peacefully.

Conditionally Load a Module
----
require behaves just like any other function in JavaScript. It has no special properties. This means that you can choose to call it based on some condition and therefore load the module only if you need it, as shown in Listing 3-6.

Listing 3-6. Code Snippet to Lazy Load a Module
if(iReallyNeedThisModule){
     var foo = require('./foo');
}

This allows you to lazy load a module only on first use, based on your requirements.

Blocking
----
The require function blocks further code execution until the module has been loaded. This means that the code following the require call is not executed until the module has been loaded and executed. This allows you to avoid providing an unnecessary callback like you need to do for all async I/O in Node.js, which was discussed in Chapter 2. (See Listing 3-7.)

Listing 3-7. Code Snippet to Demonstrate That Modules Are Loaded Synchronously
// Blocks execution till module is loaded
var foo = require('./foo');

// Continue execution after it is loaded
console.log('loaded foo');
foo();

Cached
----
As you know from Chapter 2, reading something from the file system is an order of magnitude slower than reading it from RAM. Hence, after the first time a require call is made to a particular file, the module.exports is cached. The next time a call is made to require that resolves to the same file (in other words, it does not matter what the original relative file path passed to the require call is as long as the destination file is the same), the module.exports variable of the destination file is returned from memory, keeping things fast. Listing 3-8 shows this speed difference with a simple example.

Listing 3-8. intro/cached/bar.js
var t1 = new Date().getTime();
var foo1 = require('./foo');
console.log(new Date().getTime() - t1); // > 0

var t2 = new Date().getTime();
var foo2 = require('./foo');
console.log(new Date().getTime() - t2); // approx 0

Shared State
----
Having some mechanism to share state between modules is useful in various contexts. Since modules are cached, every module that require’s foo.js will get the same (mutable) object if we return an object foo from a module foo.js. Listing 3-9 demonstrates this process with a simple example in which we export an object. This object is modified in app.js, as shown in Listing 3-10. This modification affects what is returned by require in bar.js, as shown in Listing 3-11. This allows you to share in-memory objects between modules that are useful for things like using modules for configuration. A sample execution is shown in Listing 3-12.

Listing 3-9. intro/shared/foo.js
module.exports = {
    something: 123
};

Listing 3-10. intro/shared/app.js
var foo = require('./foo');
console.log('initial something:', foo.something); // 123

// Now modify something:
foo.something = 456;

// Now load bar:
var bas = require('./bar');

Listing 3-11. intro/shared/bar.js
var foo = require('./foo');
console.log('in another module:', foo.something); // 456

Listing 3-12. Sample Run of intro/shared/app.js
$ node app.js
initial something: 123
in another module: 456

Object Factories
----
As we have shown, the same object is returned each time a require call resolves to the same file in a Node.js process. If you want some form of new object creation mechanism for each require function call, you can export a function from the source module that returns a new object. Then require the module at your destination and call this imported function to create a new object. An example is shown in Listing 3-13 where we export a function and then use this function to create a new object, as shown in Listing 3-14.

Listing 3-13. intro/factory/foo.js
module.exports = function () {
    return {
        something: 123
    };
};

Listing 3-14. intro/factory/app.js
var foo = require('./foo');

// create a new object
var obj = foo();

// use it
console.log(obj.something); // 123

Note that you can even do this in one step (in other words, require('./foo')();)

----
Node.js Exports
----
Now that we understand require a bit more, let’s take a deeper look at module.exports.

module.exports
----
As stated earlier, each file in Node.js is a module. The items that we intend to export from a module should be attached to the module.exports variable. It is important to note that module.exports is already defined to be a new empty object in every file. That is, module.exports = {} is implicitly present. By default, every module exports an empty object, in other words, {}. (See Listing 3-15.)

Listing 3-15. intro/module.exports/app.js
console.log(module.exports); // {}

Exports Alias
----
So far, we have only been exporting a single object from a module. This can be done quite simply by assigning the object we need exported to module.exports. However, it is a common requirement to export more than one variable from a module. One way of achieving this is to create a new object literal and assign that to module.exports, as shown in Listing 3-16.

Listing 3-16. intro/exports/foo1.js
var a = function () {
    console.log('a called');
};

var b = function () {
    console.log('b called');
};

module.exports = {
    a: a,
    b: b
};

However, this is slightly cumbersome to manage because what the module returns can potentially be distant in terms of lines from what a module contains. In Listing 3-16, function a is defined a lot earlier than the point at which we actually export it to the outside world. So a common convention is to simply attach the objects we want to export to module.exports inline, as shown in Listing 3-17. This is possible because module.exports is implicitly set to {} by Node.js, as we saw earlier in Listing 3-15.

Listing 3-17. intro/exports/foo2.js
module.exports.a = function () {
    console.log('a called');
};

module.exports.b = function () {
    console.log('b called');
};

However, typing module.exports all the time becomes cumbersome as well. So Node.js helps us by creating an alias for module.exports called exports so instead of typing module.exports.something every time, you can simply use exports.something. This is shown in Listing 3-18.

Listing 3-18. intro/exports/foo3.js
exports.a = function () {
    console.log('a called');
};

exports.b = function () {
    console.log('b called');
};

It is important to note that exports is just like any other JavaScript variable; Node.js simply does exports = module.exports for us. If we add something  for example, foo to exports, that is exports.foo = 123, we are effectively doing module.exports.foo = 123 since JavaScript variables are references, as discussed in Chapter 2.

However, if you do exports = 123, you break the reference to module.exports; that is, exports no longer points to module.exports. Also, it does not make module.exports = 123. Therefore, it is very important to know that you should only use the exports alias to attach stuff and not assign stuff to it directly. If you want to assign a single export, use module.exports =  as we have been doing until this section.

Finally, you can run the code sample shown in Listing 3-19 to demonstrate that all of these methods are equivalent from consumption (import) point of view.

Listing 3-19. intro/exports/app.js
var foo1 = require('./foo1');
foo1.a();
foo1.b();

var foo2 = require('./foo2');
foo2.a();
foo2.b();

var foo3 = require('./foo3');
foo3.a();
foo3.b();

----
Modules Best Practices
----
Now that we understand the technology behind the Node.js file-based module system, let’s look at a few best practices followed by the community. Node.js and JavaScript are quite resilient to programming errors and try to be flexible, which is why there are various ways that work. However, you should follow some conventions, and we highlight a few that are common in the community.

Do Not Use the .js Extension
----
It is better to do require('./foo') instead of require('./foo.js') even though both work fine for Node.js.

Reason: For browser-based module systems (such as RequireJS, which we look at later in this chapter), it is assumed that you do not provide the .js extension since we cannot look at the server filesystem to see what you meant. For the sake of consistency, avoid adding the .js extension in all your require calls.

Relative Paths
----
When using file-based modules, you need to use relative paths (in other words, do require('./foo') instead of require('foo')).

Reason: Non-relative paths are reserved for core modules and node_modules. We discuss core modules in this chapter and node_modules in the next chapter. 

Utilize exports
----
Try and use the exports alias when you want to export more than one thing.

Reason: It keeps what is exported close to its definition. It is also conventional to have a local variable for each thing you export so that you can easily use it locally. Do this all in a single line, as shown in Listing 3-20.

Listing 3-20. Create a Local Variable and Also Export
var foo = exports.foo = /* whatever you want to export as `foo` from this module */ ;

Export an Entire Folder
----
If you have too many modules that go together that you keep importing into other files, try to avoid repeating the import, as shown in Listing 3-21.

Listing 3-21. Avoid Repeating Huge Import Blocks
var foo = require('../something/foo');
var bar = require('../something/bar');
var bas = require('../something/bas');
var qux = require('../something/qux');

Instead, create a single index.js in the something folder. In index.js, import all the modules once and then export them from this module, as shown in Listing 3-22.

Listing 3-22. Sample index.js
exports.foo = require('./foo');
exports.bar = require('./bar');
exports.bas = require('./bas');
exports.qux = require('./qux');

Now you can simply import this index.js whenever you need all these things:

var something = require('../something/index');

Reason: It is more maintainable. On the export side, individual modules (individual files) remain smaller—you do not need to put everything into a single file just so you can import it easily elsewhere. You just need to create an index.js file. On the import side, you have fewer require calls to write (and maintain).


----
3.2 Important Globals
----
Node.js provides a fair number of globally available utility variables. Some of these variables are true globals (shared between all modules) and some are local globals (variables specific to the current module). We have already seen an example of a few true globals, the require function. And we have seen a few module-level implicitly defined variables—module (used by module.exports) and exports. Let us examine a few more important globals.

----
console
----
console is one of the most useful globals available. Since it is so easy to start and restart a Node.js application from the command line, the console plays an important part in quickly showing what is happening in your application when you need to debug it. We have been using console.log throughout our examples for the same exact purpose. console has a lot more o functions, which we discuss in Chapter 11.

----
Timers
----
We’ve seen setTimeout before when we were discussing the Node.js event loop in Chapter 2. It sets up a function to be called after a specified delay in milliseconds. Note that this delay is the minimum interval after which the specified function is called. The actual duration after which it will be called depends upon the availability of the JavaScript thread as we saw in the section on thread starvation in Chapter 2. It also depends upon when the operating system schedules the Node.js process to execute (normally not an issue). A quick example of setTimeout, which calls a function after 1,000 milliseconds (in other words, one second) is shown in Listing 3-23.

Listing 3-23. globals/timers/setTimeout.js
setTimeout(function () {
    console.log('timeout completed');
}, 1000);

Similar to the setTimeout function is the setInterval function. setTimeout only executes the callback function once after the specified duration. But setInterval calls the callback repeatedly after every passing of the specified duration. This is shown in Listing 3-24 where we print out second passed after every second. Similar to setTimeout, the actual duration may exceed the specified value depending on the availability of the JavaScript thread.

Listing 3-24. globals/timers/setInterval.js
setInterval(function () {
    console.log('second passed');
}, 1000);

Both setTimeout and setInterval return an object that can be used to clear the timeout/interval using the clearTimeout/clearInterval functions. Listing 3-25 demonstrates how to use clearInterval to call a function after every second for five seconds, and then clear the interval after which the application will exit.

Listing 3-25. globals/timers/clearInterval.js
var count = 0;
var intervalObject = setInterval(function () {
    count++;
    console.log(count, 'seconds passed');
    if (count == 5) {
        console.log('exiting');
        clearInterval(intervalObject);
    }
}, 1000);

----
__filename and __dirname
----
These variables are available in each file and give you the full path to the file and directory for the current module. Being full paths means that they include everything right up to the root of the current drive this file resides on. Use the code in Listing 3-26 to see these values change as you move the file to different locations on your filesystem and run it.

Listing 3-26. globals/fileAndDir/app.js
console.log(__dirname);
console.log(__filename);

----
process
----
process is one of the most important globals provided by Node.js. In addition to a few useful member functions and properties that we will examine in the next section, it is a source of a few critical events that we examine in Chapter 5 when we take a deeper look at events.

Command Line Arguments
---
Since Node.js does not have a main function in the traditional C/C++/JAVA/C# sense, you use the process object to access the command line arguments. The arguments are available as the process.argv member property, which is an array. The first element is node (that is, the node executable), the second element is the name of the JavaScript file passed into Node.js to start the process, and the remaining elements are the command line arguments. As an example, consider a simple file argv.js, which simply logs these out to the console as shown in Listing 3-27. If you run it as node argv.js foo bar bas, you will get output similar to what is shown in Listing 3-28.

Listing 3-27. globals/process/argv.js
// argv.js
console.log(process.argv);

Listing 3-28. Sample Output from argv.js
 ['node',
  '/path/to/file/on/your/filesystem/argv.js',
  'foo',
  'bar',
  'bas']

Some excellent libraries exist for processing the command line arguments in a meaningful way in Node.js. We will examine one such library when we learn more about NPM in the next chapter.

process.nextTick
----
process.nextTick is a simple function that takes a callback function. It is used to put the callback into the next cycle of the Node.js event loop. It is designed to be highly efficient, and it is used by a number of Node.js core libraries. Its usage is simple enough to demonstrate, and an example is shown in Listing 3-29. The output from this sample is shown in Listing 3-30.

Listing 3-29. globals/process/nexttick.js
// nexttick.js
process.nextTick(function () {
    console.log('next tick');
});
console.log('immediate');

Listing 3-30. Sample nexttick.js output
immediate
next tick

As you can see, the immediate call is executed first, whereas the nextTick callback is executed in the next run of the event loop. The reason why you should be aware of this function is because, due to the async nature of Node.js, this function will show up in the call stack quite commonly as this will be the starting point of a Node.js event loop. Everything before this function is in C. Everything after this function in the call stack is in JavaScript.

----
Buffer
----
Buffer World! Pure JavaScript is great for Unicode strings. However, to work with TCP streams and the file system, the developers added native and fast support to handle binary data. The developers did this in Node.js using the Buffer class, which is available globally.

As a Node.js developer working on applications, your main interaction with buffer will most likely be in the form of converting Buffer instances to string or strings to Buffer instances. In order to do either of these conversions, you need to need to tell the Buffer class about what each character means in terms of bytes. This information is called character encoding. Node.js supports all the popular encoding formats like ASCII, UTF-8, and UTF-16.

Converting strings to buffers is really simple. You just call the Buffer class constructor (see prototype discussion in Chapter 2 to review classes in JavaScript) passing in a string and an encoding. Converting a Buffer instance to a string is just as simple. You call the Buffer instance’s toString method passing in an encoding scheme. Both of these are demonstrated in Listing 3-31.

Listing 3-31. globals/buffer/buffer.js
// a string
var str = "Hello Buffer World!";

// From string to buffer
var buffer = new Buffer(str, 'utf-8');

// From buffer to string
var roundTrip = buffer.toString('utf-8');
console.log(roundTrip); // Hello

----
global
----
The variable global is our handle to the global namespace in Node.js. If you are familiar with front-end JavaScript development, this is somewhat similar to the window object. All the true globals we have seen (console, setTimeout, and process) are members of the global variable. You can even add members to the global variable to make it available everywhere, as shown in Listing 3-32. The fact that this makes the variable something available everywhere is demonstrated in Listing 3-33.

Listing 3-32. globals/global/addToGlobal.js
global.something = 123;

Listing 3-33. globals/global/app.js
console.log(console === global.console);       // true
console.log(setTimeout === global.setTimeout); // true
console.log(process === global.process);       // true

// Add something to global
require('./addToGlobal');
console.log(something); // 123

Even though adding a member to global is something that you can do, it is strongly discouraged. The reason is that it makes it extremely difficult to know where a particular variable is coming from. The module system is designed to make it easy to analyze and maintain large codebases. Having globals all over the place is not maintainable, scalable, or reusable without risk. It is, however, useful to know the fact that it can be done and, more importantly, as a library developer you can extend Node.js any way you like.


----
3.3 Core Modules
----
The Node.js design philosophy is to ship with a few battle-tested core modules and let the community build on these to provide advanced functionality. In this section, we examine a few of the important core modules.

----
Consuming Core Modules
----
Consuming core modules is very similar to consuming file-based modules that you write yourself. You still use the require function. The only difference is that instead of a relative path to the file, you simply specify the name of the module to the require function. For example, to consume the core path module, you write a require statement like var path = require('path'). As with file-based modules, there is no implicit global namespace pollution and what you get is a local variable that you name yourself to access the contents of the module. For example, in var path = require('path') we are storing it in a local variable called path. Now let’s examine a few core modules that you should be aware of to be successful with Node.js.

----
Path Module
----
Use require('path') to load this module. The path module exports functions that provide useful string transformations common when working with the file system. The key motivation for using the path module is to remove inconsistencies in handling file system paths. For example, path.join uses the forward slash `/` on UNIX-based systems like Mac OS X vs. backward slash `\` on Windows systems. Here is a quick discussion and sample of a few of the more useful functions.

path.normalize(str)
----
This function fixes up slashes to be OS specific, takes care of . and .. in the path, and also removes duplicate slashes. A quick example to demonstrate these features is shown in Listing 3-34.

Listing 3-34. core/path/normalize.js
var path = require('path');

// Fixes up .. and .
// logs on Unix: /foo
// logs on Windows: \foo
console.log(path.normalize('/foo/bar/..'));

// Also removes duplicate '//' slashes
// logs on Unix: /foo/bar
// logs on Windows: \foo\bar
console.log(path.normalize('/foo//bar/bas/..'));

path.join([str1], [str2], …)
----
This function joins any number of paths together, taking into account the operating system. A sample is shown in Listing 3-35.

Listing 3-35. core/path/join.js
var path = require('path');

// logs on Unix: foo/bar/bas
// logs on Windows: foo\bar\bas
console.log(path.join('foo', '/bar', 'bas'));

dirname, basename, and extname
----
These functions are three of the most useful functions in the path module. path.dirname gives you the directory portion of a specific path string (OS independent), and path.basename gives you the name of the file. path.extname gives you the file extension. An example of these functions is shown in Listing 3-36.

Listing 3-36. core/path/dir_base_ext.js
var path = require('path');

var completePath = '/foo/bar/bas.html';

// Logs : /foo/bar
console.log(path.dirname(completePath));

// Logs : bas.html
console.log(path.basename(completePath));

// Logs : .html
console.log(path.extname(completePath));

You should now have an understanding of how to use path and what its design goals are. Path has a few other useful functions that you can explore online using the official Node.js documentation (http://nodejs.org/api/path.html).

----
fs Module
----
The fs module provides access to the filesystem. Use require('fs') to load this module. The fs module has functions for renaming files, deleting files, reading files, and writing to files. A simple example to write to the file system and read from the file system is shown in Listing 3-37.

Listing 3-37. core/fs/create.js
var fs = require('fs');

// write
fs.writeFileSync('test.txt', 'Hello fs!');

// read
console.log(fs.readFileSync('test.txt').toString());

One of the great things about the fs module is that it has asynchronous as well as synchronous functions (using the -Sync postfix) for dealing with the file system. As an example, to delete a file you can use unlink or unlinkSync. A synchronous version is shown in Listing 3-38, and an asynchronous version of the same code is shown in Listing 3-39.

Listing 3-38. core/fs/deleteSync.js
var fs = require('fs');
try {
    fs.unlinkSync('./test.txt');
    console.log('test.txt successfully deleted');
}
catch (err) {
    console.log('Error:', err);
}

Listing 3-39. core/fs/delete.js
var fs = require('fs');
fs.unlink('./test.txt', function (err) {
    if (err) {
        console.log('Error:', err);
    }
    else {
        console.log('test.txt successfully deleted');
    }
});

The main difference is that the async version takes a callback and is passed the error object if there is one. We discussed this convention of error handling using a callback and an error argument in Chapter 2.

We also saw in Chapter 2 that accessing the file system is an order of magnitude slower than accessing RAM. Accessing the filesystem synchronously blocks the JavaScript thread until the request is complete. It is better to use the asynchronous functions whenever possible in busy processes such as in a web server scenario.

More information about the fs module can be found online in the official Node.js documentation (http://nodejs.org/api/fs.html).

----
os Module
----
The os module provides a few basic (but vital) operating-system related utility functions and properties. You can access it using a require('os') call. For example, if we want to know the current system memory usage, we can use os.totalmem() and os.freemem() functions. These are demonstrated in Listing 3-40.

Listing 3-40. core/os/memory.js
var os = require('os');
var gigaByte = 1 / (Math.pow(1024, 3));
console.log('Total Memory', os.totalmem() * gigaByte, 'GBs');
console.log('Available Memory', os.freemem() * gigaByte, 'GBs');
console.log('Percent consumed', 100 * (1 - os.freemem() / os.totalmem()));

A vital facility provided by the os module is information about the number of CPUs available, as shown in Listing 3-41.

Listing 3-41. core/os/cpus.js
var os = require('os');
console.log('This machine has', os.cpus().length, 'CPUs');

We will learn how to take advantage of this fact in Chapter 13 when we discuss scalability.

----
util Module
----
The util module contains a number of useful functions that are general purpose. You can access the util module using a require('util') call. To log out something to the console with a timestamp, you can use the util.log function, as shown in Listing 3-42.

Listing 3-42. core/util/log.js
var util = require('util');
util.log('sample message'); // 27 Apr 18:00:35 - sample message

Another extremely useful feature is string formatting using the util.format function. This function is similar to the C/C++ printf function. The first argument is a string that contains zero or more placeholders. Each placeholder is then replaced using the remaining arguments based on the meaning of the placeholder. Popular placeholders are %s (used for strings) and %d (used for numbers). These are demonstrated in Listing 3-43.

Listing 3-43. core/util/format.js
var util = require('util');
var name = 'nate';
var money = 33;

// prints: nate has 33 dollars
console.log(util.format('%s has %d dollars', name, money));

Additionally, util has a few functions to check if something is of a particular type (isArray, isDate, isError). These functions are demonstrated in Listing 3-44.

Listing 3-44. core/util/isType.js
var util = require('util');
console.log(util.isArray([])); // true
console.log(util.isArray({ length: 0 })); // false

console.log(util.isDate(new Date())); // true
console.log(util.isDate({})); // false

console.log(util.isError(new Error('This is an error'))); // true
console.log(util.isError({ message: 'I have a message' })); // false


----
3.4 Reusing Node.js Code in the Browser
----
Before we learn how to reuse Node.js code in the browser, we need to learn a bit more about the various module systems. We need to understand the need for AMD and what differentiates it from CommonJS.

----
Introducing AMD
----
As we discussed in the beginning of this chapter, Node.js follows the CommonJS module specification. This module system is great for the server environment when we have immediate access to the file system. We discussed that loading a module from the file system in Node.js is a blocking call for the first time. Consider the simple case of loading two modules, as shown in Listing 3-45.

Listing 3-45. Code Snippet to Show Loading Two Modules Using CommonJS
var foo = require('./foo');
var bar = require('./bar');
// continue code here

In this example bar.js is not parsed until all of foo.js has been loaded. In fact, Node.js doesn’t even know that you will need bar.js until foo.js is loaded and the line require('./bar') is parsed. This behavior is acceptable in a server environment where it is considered a part of the bootstrap process for your application. You mostly require things when starting your server and afterward these are returned from memory.

However, if the same module system is used in the browser, each require statement would need to trigger an HTTP request to the server. This is an order of magnitude slower and less reliable than a file system access call. Loading a large number of modules can quickly degrade the user experience in the browser. The solution is async, in-parallel, and upfront loading of modules. To support this async loading, we need a way to declare that this file will depend upon ./foo and ./bar upfront and continue code execution using a callback. There is already a specification for exactly this called async module definition (AMD). The same example from Listing 3-45 in AMD format is shown in Listing 3-46.

Listing 3-46. code snippet to show loading two modules using AMD
define(['./foo', './bar'], function(foo, bar){
        // continue code here
});

The define function is not native to the browser. These must be provided by a third-party library. The most popular of these for the browser is RequireJS (http://requirejs.org/).

To reiterate, the browser has different latency requirements from a server startup. This necessitates a different syntax for loading modules in an async manner. The different nature of the require call is what makes reusing Node.js code in the browser slightly more involved. Before we dig deeper, let’s set up a RequireJS bootstrap application.

----
Setting Up RequireJS
----
Since we need to serve HTML and JavaScript to a web browser, we need to create a basic web server. We will be using Chrome as our browser of choice as it is available on all platforms and has excellent developer tools support. The source code for this sample is available in the chapter3/amd/base folder.

Starting the Web Server
----
We will be using server.js, which is a very basic HTTP web server that we will write ourselves in Chapter 6. Start the server using Node.js (node server.js). The server will start listening for incoming requests from the browser on port 3000. If you visit http://localhost:3000, the server will try to serve index.html from the same folder as server.js if it is available.

Download RequireJS
----
You can download RequireJS from the official web site (http://requirejs.org/docs/download.html). It is a simple JavaScript file that you can include in your project. It is already present in chapter3/amd/base folder.

Bootstrapping RequireJS
----
Create a simple index.html in the same folder as server.js with the contents shown in Listing 3-47.

Listing 3-47. amd/base/index.html
<html>
<script
    src="./require.js"
    data-main="./client/app">
</script>
<body>
    <p>Press Ctrl + Shift + J (Windows) or Cmd + Opt + J (MacOSX) to open up the console</p>
</body>
</html>

We have a simple script tag to load require.js. When RequireJS loads, it looks at the data-main attribute on the script tag that loaded RequireJS and considers that as the application entry point. In our example, we set the data-main attribute to ./client/app and therefore RequireJS will try and load http://localhost:3000/client/app.js.

Client-Side Application Entry Point
----
As we set up RequireJS to load /client/app.js, let’s create a client folder and an app.js inside that folder that simply logs out something to the console, as shown in Listing 3-48.

Listing 3-48. amd/base/client/app.js
console.log('Hello requirejs!');

Now if you open up the browser http://localhost:3000 and open the dev tools (press F12), you should see the message logged to the console, as shown in Figure 3-1.

Figure 3-1. basic AMD sample

That is the basics of setting up RequireJS. This setup will be used in the remaining demos in this section. You only need to copy this server.js + index.html + require.js + client/app.js combination and start hacking to your heart's content.

There are a lot more configuration options for RequireJS and you are encouraged to explore the API documentation that is available online at http://requirejs.org/docs/api.html.

----
Playing with AMD
----
Now that we know how to start a RequireJS browser application, let’s see how we can import/export variables in modules. We will create three modules: app.js, foo.js, and bar.js. We will use foo.js and bar.js from app.js using AMD. This demo is available in chapter3/amd/play folder.

To export something from a module, you can simply return it from the define callback. For example, let’s create a file foo.js that exports a simple function, as shown in Listing 3-49.

Listing 3-49. amd/play/client/foo.js
define([], function () {
    var foo = function () {
        console.log('foo was called');
    };
    return foo; // function foo is exported
});

To be upfront about all the modules we need in a file, the root of the file contains a call to define. To load  modules ./foo and ./bar in app.js in the same folder, the define call will be as shown in Listing 3-50.

Listing 3-50. amd/play/client/app.js
define(['./foo', './bar'], function (foo, bar) {
        // use foo and bar here
});

The function define can take a special argument called exports, which behaves similar to the exports variable in Node.js. Let’s create the module bar.js using this syntax, as shown in Listing 3-51.

Listing 3-51. amd/play/client/bar.js
define(['exports'], function (exports) {
    var bar = exports.log = function () {
        console.log('bar.log was called');
    };
});

Note that you can only use exports to attach variables you want to export (for example, exports.log = /*something*/), but you cannot assign it to something else (exports = /*something*/) as that would break the reference the exports variable monitored by RequireJS. This is conceptually quite similar to the exports variable in Node.js. Now, let’s complete app.js and consume both of these modules, as shown in Listing 3-52.

Listing 3-52. amd/play/client/app.js
define(['./foo', './bar'], function (foo, bar) {
    foo();
    bar.log();
});

If you run this application, you get the desired result shown in Figure 3-2.

Figure 3-2. foo and bar used from app.js

The real benefit of using this alternate (AMD) syntax for modules becomes evident when we look at the network tab within the chrome debug tools, as shown in Figure 3-3.

Figure 3-3. basic AMD sample

You can see that foo.js and bar.js were downloaded in parallel as soon as app.js was downloaded, and RequireJS found that app.js needs foo.js and bar.js to function because of the call to define.

More about AMD
----
Here are a few useful and interesting facts that you should know about AMD to complete your knowledge:
- Modules are cached. This is similar to how modules are cached in Node.js—that is, the same object is returned every time.
- Many of these arguments to define are optional and there are various ways to configure how modules are scanned in RequireJS.
- You can still do conditional loading of specific modules using a require call, which is another function provided by RequireJS as shown in Listing 3-53. This function is also async and is different from the Node.js version of require.

Listing 3-53. Snippet to show how you can conditionally load a module in AMD
define(['./foo', './bar'], function(foo, bar){
        if(iReallyNeedThisModule){
                require(['./bas'], function(bas){
                        // continue code here.
                });
        }
});

The objective here was to give a quick overview of how you can use RequireJS and understand that the browser is different from Node.js.

----
Converting Node.js Code into Browser Code
----
As you can see, there are significant differences between the browser module systems (AMD) and the Node.js module system (CommonJS). However, the good news is that the Node.js community has developed a number of tools to take your CommonJS / Node.js code and transform it to be AMD / RequireJS compatible. The most commonly used one (and the one on which other tools rely) is Browserify (http://browserify.org/).

Browserify is a command line tool that is available as an NPM module. NPM modules are discussed in great detail in the next chapter. For now, it is sufficient to know that if you have Node.js installed as specified in Chapter 1, you already have npm available. To install Browserify as on the command line tool, simply execute the command shown in Listing 3-54. (Note: On Mac OS X you need to run this as root (sudo npm install –g browserify).

Listing 3-54. Installing Browserify
npm install -g browserify

This installs Browserify globally (a concept that will become clear in the next chapter) and makes it further available on the command line. Now if you run browserify, you should see output as shown in Figure 3-4 to indicate a successful installation.

Figure 3-4. Using Browserify on the command prompt

The most common way to use browserify is to specify an entry point for your Node.js module and convert that file and all of its dependencies files into a single AMD compatible file using the –o (--outfile) parameter. As always, let’s jump into a demo to get some hands-on experience.

Browserify Demo
----
In this section, we will create a few simple Node.js modules and then use Browserify to convert them to AMD syntax and run them in the browser. All of the code for this example is present in the chapter3/amd/browserify folder.

First off, we will create three files that follow the Node.js / CommonJS module specification (code is in the chapter3/amd/browserify/node folder). We are using foo.js (Listing 3-55) and bar.js (Listing 3-56) from app.js (Listing 3-57) using CommonJS. You can run this code in Node.js to see that it works as expected.

Listing 3-55. amd/browserify/node/foo.js
module.exports = function () {
    console.log('foo was called');
}

Listing 3-56. amd/browserify/node/bar.js
exports.log = function () {
    console.log('bar.log was called');
}

Listing 3-57. amd/browserify/node/app.js
var foo = require('./foo');
var bar = require('./bar');

foo();
bar.log();

Now let’s convert this code so that it is an AMD compatible module. On the command line, run the command as shown in Listing 3-58.

Listing 3-58. Command Line Arguments to Convert app.js into an AMD Module
browserify app.js -o amdmodule.js

This takes app.js and all its dependencies (foo.js and bar.js) and converts them into a single AMD compatible module amdmodule.js in the same folder. As a final step, we simply load this module from our client app.js (Listing 3-59) to show that it works in the browser.

Listing 3-59. amd/browserify/client/app.js
define(['../node/amdmodule'], function (amdmodule) {
});

Now if we start the server (server.js) and open up the web browser (http://localhost:3000), you will see the console.log messages in the chrome dev tools, as shown in Figure 3-5. We have successfully ported the Node.js code to the browser.

Figure 3-5. Reusing Node.js/CommonJS code in the browser

One thing to note is that it is not possible to convert every Node.js module into a browser module. Specifically, Node.js modules that depend on features only available on the server (such as the file system) will not work in the browser.

Browserify has a lot of options and is also able to navigate NPM packages (node_modules). You can learn more about Browserify online at http://browserify.org/.


----
3.5 Summary
----
In this chapter, we discussed a few important maintainability topics that you should be aware of in order to become a successful Node.js developer. We looked closely at require/module.exports combinations, giving you a firm understanding of the principles of Node.js modules and its simplicity. Then we discussed a few core built-in Node.js modules. (We will take a look at more of these core modules as we learn about events, streams, and specific areas such as TCP/HTTP.) Finally, we discussed the differences between AMD and CommonJS and how to reuse Node.js code in the browser.

In the next chapter, we will discuss one of the great things about Node.js—its open source ecosystem. There are packages upon packages of open source Node.js projects available, and we will show you how you can take advantage of them using NPM.



